<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Informationstheorie und Codierung | Heng</title>
    <link>https://sirlh.github.io/courses/informationstheorie-und-codierung/</link>
      <atom:link href="https://sirlh.github.io/courses/informationstheorie-und-codierung/index.xml" rel="self" type="application/rss+xml" />
    <description>Informationstheorie und Codierung</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>zh-Hans</language><lastBuildDate>Sun, 29 Aug 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://sirlh.github.io/courses/informationstheorie-und-codierung/featured.jpg</url>
      <title>Informationstheorie und Codierung</title>
      <link>https://sirlh.github.io/courses/informationstheorie-und-codierung/</link>
    </image>
    
    <item>
      <title>Vorlesung 2</title>
      <link>https://sirlh.github.io/courses/informationstheorie-und-codierung/vorlesung2/</link>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://sirlh.github.io/courses/informationstheorie-und-codierung/vorlesung2/</guid>
      <description>&lt;h3 id=&#34;主要内容&#34;&gt;主要内容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Probabilities and ensembles 概率与总体&lt;/li&gt;
&lt;li&gt;概率的运算&lt;/li&gt;
&lt;li&gt;课后练习题&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;概率与总体&#34;&gt;概率与总体&lt;/h3&gt;
&lt;p&gt;**总体（ensemble）**x 是一个3- 元组（triple）(x, Ax ,Px)，其中 x 是一个随机变量，AX 是构成这些变量的集合 Ax = {a1,a2,a3,&amp;hellip;ai}, PX是相对应与每个变量的概率的集合 Px ={P1,P2,P3&amp;hellip;}.&lt;/p&gt;
&lt;p&gt;他们的之间的关系为： 
$$\sum_{a \epsilon A_{x} }^{}P(x=a) = 1 $$&lt;/p&gt;
&lt;p&gt;对于单个元素，它的概率表示为：
$$ P(x=a1) = P(a1) = P1 $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;子集的概率&lt;/strong&gt;，假如 T 是 Ax 的一个子集，则子集T的概率可以表示为：
$$ P(T) =P(x\epsilon T)= \sum_{a \epsilon T }^{}P(x=a)$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;联合概率&lt;/strong&gt;，XY是一个总体，它的结果与两个随机变量 x,y 有关，其中x属于 Ax ={a1,a2,a3&amp;hellip;}， y 属于Ay = {b1,b2,b3&amp;hellip;}，我们称这样的总体为&lt;em&gt;联合总体&lt;/em&gt;，把P(x,y)称为 x 和 y 的联合概率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边缘概率&lt;/strong&gt;，我们可以从连个概率 P(x,y)中得到边缘概率P(x)
$$ P(x=a_{i}) = \sum_{y\epsilon A_{y}}P(x=a_{i},y) $$&lt;/p&gt;
&lt;p&gt;类似的，可以得出 y 的边缘概率为：
$$ P(y) = \sum_{x \epsilon A_{x}}P(x,y) $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;条件概率&lt;/strong&gt;，P(x=a1/y=b1)读作在给定 y = b1 的条件下，x = a1 的概率。
$$ P(x=a_{i}|y=b_{j}) = \frac{P(x=a_{i},y=b_{j})}{P(y=b_{j})}, P(y=b_{j})\neq 0$$&lt;/p&gt;
&lt;p&gt;我们可以发现，条件概率P(x/y) 是由 联合概率 P(x,y) 除以 边缘概率 P(y) 得出。&lt;/p&gt;
&lt;h3 id=&#34;概率的运算&#34;&gt;概率的运算&lt;/h3&gt;
&lt;p&gt;关于概率的运算常用的法则主要有： 乘法律，加法律，贝叶斯定理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;乘法律&lt;/strong&gt;
$$ P(x,y) = P(x|y)P(y) = P(y|x)P(x) $$
该法则也称为链式法则。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加法律&lt;/strong&gt;
$$ P(x) = \sum_{y}P(x,y) = \sum_{y}P(x|y)P(y) $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;贝叶斯定理&lt;/strong&gt;
$$ P(x|y) = \frac{P(y|x)\cdot p(x)}{P(y)} = \frac{P(y|x)\cdot p(x)}{\sum_{x&#39;}P(y|x&#39;)\cdot P(x&#39;)} $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;独立性&lt;/strong&gt;&lt;br&gt;
如果变量 x , y 相互独立，那么联合概率
$$ P(x,y) = P(x)P(y) $$&lt;/p&gt;
&lt;h3 id=&#34;练习题&#34;&gt;练习题&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;例1&lt;/strong&gt; 小明去做了新冠检测，用变量a表示健康状态，患病( a = 1 )，不患病( a=0 )，b表示检查结果，阳性(b=1)，阴性（b=0), 假设检测结果95%是可靠的，普通人患有新冠的概率是 1% ，那当检测结果呈阳性时，小明患有新冠的概率是多少？&lt;/p&gt;
&lt;iframe  src=&#34;//player.bilibili.com/player.html?aid=505817116&amp;bvid=BV1gg411F7xH&amp;cid=419052424&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; style=&#34;width: 100%; height: 56.25vw;&#34; &gt; &lt;/iframe&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://sirlh.github.io/images/ITC/t1.jpg&#34; alt=&#34;例1习题解答&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;例2&lt;/strong&gt; 共有11个罐子，标记为 u 属于 {0,1,2,3,&amp;hellip;10}, 每个罐子中有10个球,u号罐子中有u个黑球和 10-u 个白球。小明随机选择一个罐子有放回的抽球 N 次，结果是 b 次是黑球，N-b次是白球，假如一共抽了 N=10 次，其中抽到 b=3 次黑球，N-b=7 次 白球，那么小明选择的罐子是 u 的概率是多少？ u 等于多少时概率最大？&lt;/p&gt;
&lt;iframe  src=&#34;//player.bilibili.com/player.html?aid=975801826&amp;bvid=BV1Z44y147gN&amp;cid=419152047&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; style=&#34;width: 100%; height: 56.25vw;&#34; &gt; &lt;/iframe&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://sirlh.github.io/images/ITC/t2-1.jpg&#34; alt=&#34;例2习题解答-1&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://sirlh.github.io/images/ITC/t2-2.jpg&#34; alt=&#34;例2习题解答-2&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vorlesung 1</title>
      <link>https://sirlh.github.io/courses/informationstheorie-und-codierung/vorlesung1/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      <guid>https://sirlh.github.io/courses/informationstheorie-und-codierung/vorlesung1/</guid>
      <description>&lt;h3 id=&#34;主要内容&#34;&gt;主要内容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Binomial distribution 二项分布&lt;/li&gt;
&lt;li&gt;Permutations 排列组合&lt;/li&gt;
&lt;li&gt;Poisson distribution 泊松分布&lt;/li&gt;
&lt;li&gt;binary entropy function以二为底的熵函数&lt;/li&gt;
&lt;li&gt;Hamming code 汉明码&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;--binomial-distribution-二项分布&#34;&gt;- Binomial distribution 二项分布&lt;/h3&gt;
&lt;p&gt;Wir haben eine münze, die auf Kopf fällt mit Wahrscheinlichkeit f.
Wie hoch ist die Wahrscheinlichkeit für r mal Kopf bei N münze werfen?&lt;/p&gt;
&lt;p&gt;一枚硬币抛正面的概率是f，那么抛 r 次，有 N 次是正面的概率是多少？&lt;/p&gt;
&lt;h5 id=&#34;二项分布公式&#34;&gt;二项分布公式：&lt;/h5&gt;
&lt;p&gt;$$ P(r|N,f) = \binom{N}{r} f^{r}(1-f)^{N-r} $$&lt;/p&gt;
&lt;h5 id=&#34;该分布的均值&#34;&gt;该分布的均值&lt;/h5&gt;
&lt;p&gt;$$ E(r) = \sum_{r=0}^{N}P(r|N,f)r = Nf $$&lt;/p&gt;
&lt;h5 id=&#34;方差&#34;&gt;方差&lt;/h5&gt;
&lt;p&gt;$$ Var[r] = \sum_{r=0}^{N}P(r|f,N)r^{2}-(E[r])^{2} = N(1-f)f$$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;--排列组合的写法&#34;&gt;- 排列组合的写法&lt;/h3&gt;
&lt;p&gt;$$ \binom{N}{r} = \frac{N!}{r!(N-r)!} $$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;--使用泊松分布推导x-和-排列组合公式-的近似值&#34;&gt;- 使用泊松分布推导X! 和 排列组合公式 的近似值&lt;/h3&gt;
&lt;p&gt;均值为 λ 的泊松分布公司为：
$$ P(r|\lambda ) = e^{-\lambda} \frac{\lambda^{r}}{r!} $$&lt;/p&gt;
&lt;p&gt;当 λ 较大时，可使用λ的高斯分布近似取得
$$ e^{-\lambda} \frac{\lambda^{r}}{r!} \simeq  \frac{1}{\sqrt{2\pi \lambda }}e^{-\frac{(r-\lambda )^2}{2\lambda }}$$&lt;/p&gt;
&lt;p&gt;当 r = λ 时 ，代入得:
$$ e^{-\lambda} \frac{\lambda^{\lambda }}{\lambda !} \simeq  \frac{1}{\sqrt{2\pi \lambda }} $$&lt;/p&gt;
&lt;p&gt;可推出：
$$\lambda !\simeq \lambda ^{\lambda }e^{-\lambda }\sqrt{2\pi \lambda } $$&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;阶乘 X! 的近似值&lt;/strong&gt;可写成:
$$ x!\simeq x ^{x }e^{-x }\sqrt{2\pi x } $$&lt;/p&gt;
&lt;p&gt;对 X！取对数，可得：
$$ \ln x! \simeq x\ln x - x+\frac{1}{2}\ln 2\pi x $$&lt;/p&gt;
&lt;p&gt;将上式应用于排列组合上，可得：
$$\ln \binom{N}{r} = \ln\frac{N!}{(N-r!)r!} \simeq (N-r)\ln\frac{N}{N-r}+ r\ln\frac{N}{r}$$&lt;/p&gt;
&lt;p&gt;此处我们引入 &lt;em&gt;以2为底的熵函数&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;$$ H_{2}(x) = x \log \frac{1}{x} + (1-x)\log \frac{1}{(1-x)} $$&lt;/p&gt;
&lt;p&gt;则排列组合取对数后可写为：
$$ \ln \binom{N}{r} \simeq NH_{2}(r/N) $$&lt;/p&gt;
&lt;p&gt;所以，&lt;strong&gt;排列组合公式的近似值&lt;/strong&gt; 可写成：
$$ \binom{N}{r} = 2^{NH_{2}(r/N)} $$&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;重复码&#34;&gt;重复码&lt;/h3&gt;
&lt;p&gt;在信号传输过程中，往往会出现差错，为了减少差错，我们会加入一些有用的冗余信息，最简单的办法就是多传几个，类似于“重要的事情说三遍”，这就是重复码，而在译码过程中，则采用少数服从多数的办法来获取信源信息。&lt;/p&gt;
&lt;p&gt;如：重复码 R3 ，重复三次。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;源序列&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;发送序列&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;111&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;重复码的译码是少数服从多数的原则，如R3的译码表：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;接收序列&lt;/th&gt;
&lt;th style=&#34;text-align:right&#34;&gt;译码序列&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;000&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;001&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;010&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;011&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;100&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;101&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;110&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;111&lt;/td&gt;
&lt;td style=&#34;text-align:right&#34;&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;练习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设传输过程中的误差为f. 使用R3（重复3次）和R5（重复5次）的编码方式传输，出错的概率分别为多少？&lt;/p&gt;
&lt;p&gt;&lt;em&gt;重复3次的概率为&lt;/em&gt;：
$$ P = f^{2}(1-f) \binom{3}{2} + f^{3} \binom{3}{3}$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;重复5次的概率为&lt;/em&gt;：
$$ P = f^{3}(1-f)^{2} \binom{5}{3} + f^{4}(1-f)\binom{5}{4} + f^{5} \binom{5}{5}$$&lt;/p&gt;
&lt;p&gt;类似的可得出重复 N 次时，重复码的差错概率是：&lt;/p&gt;
&lt;p&gt;$$ P_{b}=\sum_{n = (N+1)/2}^{N}\binom{N}{n}f^{n}(1-f)^{N-n}$$&lt;/p&gt;
&lt;p&gt;显然，重复次数越多，误差越低，使用matlab画图可得：&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://sirlh.github.io/images/ITC/Repeat-code.png&#34; alt=&#34;重复次数与差错概率的关系&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;f = 0.5 ; %误差
T = [1:30]; % 实验次数，假定为30
  t = length(T);
Pb = zeros(1,t) ;% 差错概率，初始值设为0

for N = 1:t
    for n= ceil((N+1)/2) : N
        Pb(N) = nchoosek(N,n) * power(f,n) * power(1-f,N-n);
    end
end

plot(Pb);
title(&#39;重复次数与差错概率的关系&#39;)
xlabel(&#39;重复次数N&#39;) 
ylabel(&#39;差错概率Pb&#39;) 
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h3 id=&#34;汉明码&#34;&gt;汉明码&lt;/h3&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=463302078&amp;bvid=BV1ML411s7et&amp;cid=418536112&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; style=&#34;width: 100%; height: 56.25vw;&#34; &gt; &lt;/iframe&gt;
</description>
    </item>
    
  </channel>
</rss>
